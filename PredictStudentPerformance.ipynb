{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to files\n",
    "test_csv_path = \"../data/test.csv\"\n",
    "train_csv_path = \"../data/train.csv\"\n",
    "target_labels_csv = \"../data/train_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only session_id column\n",
    "tmp = pd.read_csv(train_csv_path, usecols=[0])\n",
    "tmp = tmp.groupby(\"session_id\")[\"session_id\"].agg(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate chunks and skips\n",
    "pieces = 25\n",
    "chunks = int(np.ceil(len(tmp) / pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pieces: 25 of sizes: [1063516, 1054835, 1100631, 1050250, 1048333, 1049923, 1059672, 1053593, 1060254, 1073360, 1041039, 1067514, 1075765, 1026458, 1064071, 1054090, 1026632, 1050203, 1023984, 1044632, 1055852, 1047718, 1040246, 1044565, 1019810]\n"
     ]
    }
   ],
   "source": [
    "reads = []\n",
    "skips = [0]\n",
    "\n",
    "for k in range(pieces):\n",
    "    a = k * chunks\n",
    "    b = (k + 1) * chunks\n",
    "\n",
    "    if b > len(tmp):\n",
    "        b = len(tmp)\n",
    "\n",
    "    r = tmp.iloc[a:b].sum()\n",
    "    reads.append(r)\n",
    "    skips.append(skips[-1] + r)\n",
    "\n",
    "print(f\"pieces: {pieces} of sizes: {reads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>3</td>\n",
       "      <td>1147</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gotta run to my meeting!</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>4</td>\n",
       "      <td>1863</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-412.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>381.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can I come, Gramps?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level  page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0   NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0   NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0   NaN   \n",
       "3  20090312431273200      3          1147    person_click  basic      0   NaN   \n",
       "4  20090312431273200      4          1863    person_click  basic      0   NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "1  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "2  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "3  -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "4  -412.991405  -159.314686          381.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
       "4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid  fullscreen  hq  music  \\\n",
       "0               tunic.historicalsociety.closet.intro           0   0      1   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
       "3  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
       "4  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  \n",
       "3         0-4  \n",
       "4         0-4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv_path, nrows=reads[0])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv(target_labels_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df[\"session\"] = target_df.session_id.apply(lambda x: int(x.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df[\"q\"] = target_df.session_id.apply(lambda x: int(x.split(\"_\")[-1][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df[\"correct\"] = target_df[\"correct\"].astype(\"int8\")\n",
    "target_df[\"q\"] = target_df[\"q\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>session</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312455206810_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090312455206810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090313091715820_q1</td>\n",
       "      <td>0</td>\n",
       "      <td>20090313091715820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090313571836404_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090313571836404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct            session  q\n",
       "0  20090312431273200_q1        1  20090312431273200  1\n",
       "1  20090312433251036_q1        0  20090312433251036  1\n",
       "2  20090312455206810_q1        1  20090312455206810  1\n",
       "3  20090313091715820_q1        0  20090313091715820  1\n",
       "4  20090313571836404_q1        1  20090313571836404  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"event_name\",\n",
    "    \"fqid\",\n",
    "    \"room_fqid\",\n",
    "    \"text\",\n",
    "    \"text_fqid\",\n",
    "]\n",
    "\n",
    "numerical_cols = [\n",
    "    \"elapsed_time\",\n",
    "    \"level\",\n",
    "    \"page\",\n",
    "    \"room_coor_x\",\n",
    "    \"room_coor_y\",\n",
    "    \"screen_coor_x\",\n",
    "    \"screen_coor_y\",\n",
    "    \"hover_duration\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cutscene_click',\n",
       "  'person_click',\n",
       "  'navigate_click',\n",
       "  'observation_click',\n",
       "  'notification_click',\n",
       "  'object_click',\n",
       "  'object_hover',\n",
       "  'map_hover',\n",
       "  'map_click',\n",
       "  'checkpoint',\n",
       "  'notebook_click'],\n",
       " 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_list = train_df[\"event_name\"].unique().tolist()\n",
    "event_list, len(event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['undefined',\n",
       "  'Whatcha doing over there, Jo?',\n",
       "  'Just talking to Teddy.',\n",
       "  'I gotta run to my meeting!',\n",
       "  'Can I come, Gramps?',\n",
       "  'Sure thing, Jo. Grab your notebook and come upstairs!',\n",
       "  'See you later, Teddy.',\n",
       "  \"I get to go to Gramps's meeting!\",\n",
       "  'Now where did I put my notebook?',\n",
       "  '\\\\u00f0\\\\u0178\\\\u02dc\\\\u00b4',\n",
       "  nan,\n",
       "  'I love these photos of me and Teddy!',\n",
       "  'Found it!',\n",
       "  'Gramps is in trouble for losing papers?',\n",
       "  \"This can't be right!\",\n",
       "  'Gramps is a great historian!',\n",
       "  \"Hmm. Button's still not working.\",\n",
       "  \"Let's get started. The Wisconsin Wonders exhibit opens tomorrow!\",\n",
       "  'Who wants to investigate the shirt artifact?',\n",
       "  \"Not Leopold here. He's been losing papers lately.\",\n",
       "  'Hey!',\n",
       "  \"It's true, they do keep going missing lately.\",\n",
       "  'See?',\n",
       "  'Besides, I already figured out the shirt.',\n",
       "  \"It's a women's basketball jersey!\",\n",
       "  'That settles it.',\n",
       "  'Wells, finish up your report.',\n",
       "  \"Leopold, why don't you help me set up in the Capitol?\",\n",
       "  'We need to talk about that missing paperwork.',\n",
       "  'Will do, Boss.',\n",
       "  \"Hey Jo, let's take a look at the shirt!\",\n",
       "  'Your grampa is waiting for you in the collection room.',\n",
       "  \"Why don't you go catch up with your grampa?\",\n",
       "  'What a fascinating artifact!',\n",
       "  \"Wow, that's so cool, Gramps!\",\n",
       "  'Can I take a closer look?',\n",
       "  \"Hmmm. Shouldn't you be doing your homework?\",\n",
       "  \"It's already all done!\",\n",
       "  'Plus, my teacher said I could help you out for extra credit!',\n",
       "  \"Well, that's good enough for me.\",\n",
       "  'Go ahead, take a peek at the shirt!',\n",
       "  'This looks like a clue!',\n",
       "  \"I'll record this in my notebook.\",\n",
       "  'Find anything?',\n",
       "  'Yes! This old slip from 1916.',\n",
       "  'I knew it!',\n",
       "  \"I'm not so sure that this is a basketball jersey.\",\n",
       "  'Wait, you mean Wells is wrong?!',\n",
       "  'Could be. But we need evidence!',\n",
       "  \"Why don't you head to the Basketball Center and rustle up some clues?\",\n",
       "  'Sure!',\n",
       "  \"I'll be at the Capitol. Let me know if you find anything!\",\n",
       "  'Better check back later.',\n",
       "  \"That's it!\",\n",
       "  \"The slip is from 1916 but the team didn't start until 1974!\",\n",
       "  'Our shirt is too old to be a basketball jersey!',\n",
       "  'I need to get to the Capitol and tell Gramps!',\n",
       "  'What are you still doing here,  Jolie?',\n",
       "  'Go find your grampa and get to work!',\n",
       "  'Oh no!',\n",
       "  'What happened here?!',\n",
       "  \"I don't know!\",\n",
       "  'I got here and the whole place was a mess!',\n",
       "  'Can you help me tidy up?',\n",
       "  \"Teddy's scarf! Somebody must've taken him!\",\n",
       "  'Try not to panic, Jo.',\n",
       "  'Maybe he just got scared and ran off.',\n",
       "  'But he never goes anywhere without his scarf!',\n",
       "  \"I think he's in trouble!\",\n",
       "  'Is this your coffee, Gramps?',\n",
       "  \"Nope, that's from Bean Town. I only drink Holdgers!\",\n",
       "  \"Who could've done this?\",\n",
       "  \"It must've been Wells.\",\n",
       "  \"He's always trying to get you in trouble, and he doesn't like animals!\",\n",
       "  'Slow down, Jo.',\n",
       "  'But what if Wells kidnapped Teddy?',\n",
       "  'Then we need evidence.',\n",
       "  \"You're right, Gramps. Let's investigate!\",\n",
       "  \"I'm afraid my papers have gone missing in this mess.\",\n",
       "  \"You'll have to get started without me.\",\n",
       "  \"Okay. I'll find Teddy!\",\n",
       "  \"And I'll figure out the shirt, too.\",\n",
       "  'I knew I could count on you, Jo!',\n",
       "  \"Why don't you go upstairs and see the archivist?\",\n",
       "  \"He's our expert record keeper.\",\n",
       "  'I need your help!',\n",
       "  'Who are you?',\n",
       "  \"I'm Leopold's grandkid!\",\n",
       "  \"Sorry, I'm too busy for kids right now.\",\n",
       "  'Now if only I could read this thing.',\n",
       "  \"Can't believe I lost my reading glasses.\",\n",
       "  'I bet the archivist could use this!',\n",
       "  \"Ah, that's better!\",\n",
       "  'Did you have a question?',\n",
       "  'Yes! I was wondering-',\n",
       "  'Wait a minute!',\n",
       "  'Where did you get that coffee?',\n",
       "  \"Oh, that's from Bean Town.\",\n",
       "  'I ran into Wells there this morning.',\n",
       "  'Wells? I knew it!',\n",
       "  'Do you know anything about this slip?',\n",
       "  'I found it on an old shirt.',\n",
       "  'An old shirt? Try the university.',\n",
       "  'You can talk to a textile expert there.',\n",
       "  \"What's a textile expert?\",\n",
       "  'They study clothes and fabric.',\n",
       "  'Great! Thanks for the help!',\n",
       "  'Head over to the university.',\n",
       "  'Hello there!',\n",
       "  'Wow! What is all this stuff?',\n",
       "  \"It's our Norwegian Craft exhibit!\",\n",
       "  'Can I give you the tour?',\n",
       "  \"Sorry, I'm in a hurry.\",\n",
       "  'Do you know what this slip is?',\n",
       "  'Looks like a dry cleaning receipt.',\n",
       "  'Thanks.',\n",
       "  'Now I Just need to find all the cleaners from way back in 1916.',\n",
       "  'Maybe I can help!',\n",
       "  \"I've got a stack of business cards from my favorite cleaners.\",\n",
       "  \"Why don't you take a look?\",\n",
       "  'This place was around in 1916! I can start there!',\n",
       "  \"You haven't seen any badgers around here, have you?\",\n",
       "  'Badgers? No.',\n",
       "  'Okay. Thanks anyway.',\n",
       "  'Hi! How can I help you?',\n",
       "  'I need to find the owner of this slip.',\n",
       "  \"Well, I can't show our log books to just anybody.\",\n",
       "  'Please?',\n",
       "  \"It's for Grampa Leo. He's a historian!\",\n",
       "  'Leo... you mean Leopold?',\n",
       "  'Your gramps is awesome! Always full of stories.',\n",
       "  \"Guess it couldn't hurt to let you take a look.\",\n",
       "  \"Here's the log book.\",\n",
       "  \"It's a match!\",\n",
       "  'Theodora Youmans must be the owner!',\n",
       "  'Do you know who Theodora Youmans is?',\n",
       "  \"Hmmm... not sure. Why don't you try the library?\",\n",
       "  'Thanks for the help!',\n",
       "  'Oh, hello there!',\n",
       "  'How can I help you?',\n",
       "  'Have you seen a badger around here?',\n",
       "  \"I'm afraid not.\",\n",
       "  'Please let me know if you do.',\n",
       "  \"I'm also looking for Theodora Youmans. Have you heard of her?\",\n",
       "  'Theodora Youmans? Of course!',\n",
       "  \"Check out our microfiche. It's right through that door.\",\n",
       "  'Youmans was a suffragist!',\n",
       "  'She helped get votes for women!',\n",
       "  'Wells! What was he doing here? I should ask the librarian.',\n",
       "  'What was Wells doing here?',\n",
       "  'He was looking for a taxidermist.',\n",
       "  \"What's a taxidermist?\",\n",
       "  'Not sure. Here, let me look it up.',\n",
       "  '\\\\Taxidermy: the art of preparing, stuffing, and mounting the skins of animals.\\\\',\n",
       "  'Oh no... Teddy!',\n",
       "  'Can you help me find Wells?',\n",
       "  'You could ask the archivist. He knows everybody!',\n",
       "  \"Jolie! I was hoping you'd stop by. Any news on the shirt artifact?\",\n",
       "  \"I haven't quite figured it out just yet...\",\n",
       "  \"Well, get on it. I'm counting on you and your gramps to figure this out!\",\n",
       "  'Can you help me? I need to find Wells!',\n",
       "  \"I haven't seen him.\",\n",
       "  'Please? This is really important.',\n",
       "  \"Sorry, can't help you.\",\n",
       "  'Do you have any info on Theodora Youmans?',\n",
       "  'Theodora Youmans? Is that who owned the shirt?',\n",
       "  'Yep.',\n",
       "  \"Why didn't you say so?\",\n",
       "  'Youmans was a suffragist here in Wisconsin.',\n",
       "  'She led marches and helped women get the right to vote!',\n",
       "  \"Wait a sec. Women couldn't vote?!\",\n",
       "  'Nope. But Youmans and other suffragists worked hard to change that.',\n",
       "  'Thanks to them, Wisconsin was the first state to approve votes for women!',\n",
       "  'Wow!',\n",
       "  \"Here's a call number to find more info in the Stacks.\",\n",
       "  'Where are the Stacks?',\n",
       "  'Right outside the door.',\n",
       "  'Hey, this is Youmans!',\n",
       "  \"And look! She's wearing the shirt!\",\n",
       "  'I should go to the Capitol and tell everyone!',\n",
       "  'Jo!',\n",
       "  'Check out the next artifact!',\n",
       "  'What is it?',\n",
       "  \"I think it's a flag! Pretty interesting, huh?\",\n",
       "  \"It's really cool, Gramps. But I'm worried about Teddy.\",\n",
       "  \"He's still missing!\",\n",
       "  \"We'll find him, Jo.\",\n",
       "  'Want to look for more clues?',\n",
       "  \"We'll find Teddy.\",\n",
       "  'We just have to keep our eyes open!',\n",
       "  'Hey, look at those scratches!',\n",
       "  'The kidnapper probably took Teddy on the elevator!',\n",
       "  \"You're right, Jo!\",\n",
       "  \"Why isn't the button working?\",\n",
       "  \"We'll need a key card.\",\n",
       "  'I had one, but Teddy chewed it up.',\n",
       "  \"I've got Wells's ID!\",\n",
       "  'What should we do next?',\n",
       "  \"I need to take the artifact upstairs. Why don't you investigate those scratch marks?\",\n",
       "  \"Okay. I'll try.\",\n",
       "  'Teddy, here I come!',\n",
       "  'I wonder whose glasses these are.',\n",
       "  'Teddy!!!',\n",
       "  \"Hang on. I'll get you out of there!\",\n",
       "  'Whoever lost these glasses probably took Teddy!',\n",
       "  'How can I find out whose glasses these are?',\n",
       "  'Oh! There was a staff directory in the entryway!',\n",
       "  \"I'll go look at everyone's pictures!\",\n",
       "  'Those are the same glasses!',\n",
       "  \"The archivist must've taken Teddy!\",\n",
       "  \"Yes! It's the key for Teddy's cage!\",\n",
       "  'I found the key!',\n",
       "  \"Come on, let's get out of here!\",\n",
       "  \"Here's your scarf back!\",\n",
       "  'What are you doing down here?',\n",
       "  'And how did that badger get free?',\n",
       "  \"I'm here to rescue my friend!\",\n",
       "  \"What's going on here?\",\n",
       "  'Thanks for coming, Boss.',\n",
       "  'I told you!',\n",
       "  'I captured a badger in our museum!',\n",
       "  \"He's been eating my lunch every day this week!\",\n",
       "  'He has??',\n",
       "  \"I've seen him eating homework and important papers, too.\",\n",
       "  \"Jolie- keep your badger under control, or he'll have to go.\",\n",
       "  'And you, Frank-',\n",
       "  \"You can't just steal Jolie's pet.\",\n",
       "  'Ugh. Fine.',\n",
       "  'Alright, Jolie. Back to work.',\n",
       "  \"Come on, Teddy. Let's go help Gramps!\",\n",
       "  \"Let's go help Gramps!\",\n",
       "  'Gramps must be up in the collection room.',\n",
       "  \"Let's go find him!\",\n",
       "  \"Teddy! I'm glad to see you.\",\n",
       "  'The archivist had him locked up!',\n",
       "  'Poor badger.',\n",
       "  \"You're becoming quite the detective, Jo.\",\n",
       "  'Notice any clues about this flag?',\n",
       "  'Well... it looks hand-stitched.',\n",
       "  'Good catch!',\n",
       "  'Go on, tell the boss what you found!',\n",
       "  \"I'm telling you, Boss. Taxidermy is the way to go!\",\n",
       "  'Nonsense. I want live animals at the exhibit, not stuffed ones.',\n",
       "  \"Ah, Jolie! I'm glad you're here.\",\n",
       "  \"I'm putting you in charge of the flag case.\",\n",
       "  'Make sure to get some old photos for the exhibit, like last time!',\n",
       "  \"Wait! Can't I do it?\",\n",
       "  'The symbol on the flag looks sort of like a deer hoof.',\n",
       "  'It could be an early design for the Wisconsin state flag!',\n",
       "  'Wells, you already have a job to do.',\n",
       "  'What now, kid?',\n",
       "  'Do you really think that symbol is a deer hoof?',\n",
       "  'Not sure.',\n",
       "  'Do you know where I can find a deer expert?',\n",
       "  'Hmm. You could try the Aldo Leopold Wildlife Center.',\n",
       "  'I have to head over there and check out the animals.',\n",
       "  \"I'll ride with you!\",\n",
       "  \"Come on, kid. Let's go.\",\n",
       "  'Head over to the Wildlife Center!',\n",
       "  \"I'm sure they'll be able to help.\",\n",
       "  'People sure drink a lot of coffee around here.',\n",
       "  \"I can't believe this.\",\n",
       "  'Ugh...',\n",
       "  'Oh no! What happened to that crane?',\n",
       "  'Her beak is stuck in a coffee cup.',\n",
       "  \"It's lucky we found her.\",\n",
       "  'Ugh! Those cups are all over the place.',\n",
       "  \"I need to get her free. She won't hold still!\",\n",
       "  'Can Teddy and I help?',\n",
       "  'Sure! Give it a try.',\n",
       "  'Careful. That beak is sharp!',\n",
       "  'We need to calm her down, Teddy.',\n",
       "  'Any ideas?',\n",
       "  '\\\\u00f0\\\\u0178\\\\u00a6\\\\u2014',\n",
       "  'Oh yeah, cranes eat insects!',\n",
       "  'Luckily there are tons of insects around here...',\n",
       "  'Got one!',\n",
       "  \"Maybe she'll let me take off the cup!\",\n",
       "  \"It's OK, girl! Look, I found you a cricket!\",\n",
       "  'You did it! Thanks, kid.',\n",
       "  'Can I help you with anything?',\n",
       "  \"I'm investigating this symbol.\",\n",
       "  'Does it look like a deer hoof?',\n",
       "  \"There's a diagram of animal tracks over there.\",\n",
       "  'Go take a look!',\n",
       "  \"That hoofprint doesn't match the flag!\",\n",
       "  'Thanks for your help, kid!',\n",
       "  \"So? What'd you find out?\",\n",
       "  \"Looks like it's not a deer hoof.\",\n",
       "  \"Oh no. If I don't impress the boss soon,  I'm gonna get fired!\",\n",
       "  'Hey, Wells...',\n",
       "  'I think I might be able to help you.',\n",
       "  \"No thanks. I don't need help from kids.\",\n",
       "  'Are you sure? I know where you can find a real, live badger for the exhibit!',\n",
       "  'Wait! What?! Really?',\n",
       "  'Wells, meet Teddy.',\n",
       "  '\\\\u00f0\\\\u0178\\\\u02dc\\\\u0160',\n",
       "  \"He says he'd be willing to help out.\",\n",
       "  'Yes!!!',\n",
       "  'We still need to figure out that flag. Do you know anyone who could help?',\n",
       "  \"Hmm. Let's see...\",\n",
       "  'Actually, I went to school with somebody who LOVES old flags.',\n",
       "  \"Why don't you go talk to her? I'll let her know you're coming.\",\n",
       "  'Hey, nice dog! What breed is he?',\n",
       "  \"Actually, he's a badger.\",\n",
       "  \"Oh, cool! I've never seen a badger in real life.\",\n",
       "  \"You've got a million flags here!\",\n",
       "  \"Yep. I'm a vexillophile!\",\n",
       "  \"What's a vexillophile? \",\n",
       "  'It just means flag expert. How can I help?',\n",
       "  \"I'm investigating this flag.\",\n",
       "  'Can you take a look?',\n",
       "  \"Hey, I've seen that symbol before! Check it out!\",\n",
       "  '\\\\Ecology flag, by Ron Cobb.\\\\',\n",
       "  \"It's an ecology flag!\",\n",
       "  'Do you know what this flag was used for?',\n",
       "  \"I'm not sure.\",\n",
       "  \"If I were you, I'd go to the library and do some digging.\",\n",
       "  'Good idea. Thanks!',\n",
       "  'Welcome back, Dear! How can I help you?',\n",
       "  'I need to learn more about this flag!',\n",
       "  'It has something to do with ecology.',\n",
       "  'Hmm... those stripes remind me of the American flag.',\n",
       "  'Your flag must have been part of a national movement!',\n",
       "  \"Go check the microfiche. Maybe you'll find something!\",\n",
       "  \"Hey! That's Governor Nelson in front of our flag!\",\n",
       "  'I found the flag! Governor Nelson used it on the first Earth Day!',\n",
       "  'Wow! You figured it out!',\n",
       "  'Now I just need some old photos, like last time.',\n",
       "  'The boss is gonna love it!',\n",
       "  'You could try the archives.',\n",
       "  'Though the archivist might be too busy to help...',\n",
       "  'Okay. Thanks!',\n",
       "  'What are you doing here?',\n",
       "  \"We're looking for some photos.\",\n",
       "  \"It's for the flag display!\",\n",
       "  'Wait a minute...',\n",
       "  \"YOU'RE the new history detective everybody's talking about?\",\n",
       "  \"Teddy's helping too.\",\n",
       "  'What kind of photos do you need?',\n",
       "  'Something to do with ecology and Wisconsin.',\n",
       "  \"Here's a call number for the Stacks. Go find some photos.\",\n",
       "  'Look at all those activists!',\n",
       "  'This is perfect for the exhibit.',\n",
       "  'I should go to the Capitol and tell Mrs. M!',\n",
       "  'I should see what Grampa is up to!',\n",
       "  'What should I do first?',\n",
       "  'Head upstairs and talk to the archivist. He might be able to help!',\n",
       "  \"It's locked!\",\n",
       "  \"Jolie! I was hoping you'd stop by. Any news on the flag artifact?\",\n",
       "  \"Well, get on it. I'm counting on you to figure this out!\",\n",
       "  'Nice seeing you, Jolie!',\n",
       "  \"It's such a nice fall day.\",\n",
       "  'I love these photos of me and Teddy.',\n",
       "  \"Why don't you go talk to the boss?\",\n",
       "  \"She's right outside.\",\n",
       "  'My friend is a flag expert.',\n",
       "  'She should be able to help you out.',\n",
       "  'There are some old newspapers loaded up in the microfiche.',\n",
       "  'The Stacks are right outside the door. Go find some photos!',\n",
       "  'Ugh. Meetings are so boring.',\n",
       "  'Grab your notebook and come upstairs!',\n",
       "  'Hang tight, Teddy.',\n",
       "  \"I'll hurry back and then we can go exploring!\",\n",
       "  'Well, Leopold here is always losing papers...',\n",
       "  'Ha. Told you so!',\n",
       "  'Can we hurry up, Gramps?',\n",
       "  'Teddy and I were gonna go climb that huge tree out back!',\n",
       "  \"Hmmm. Don't forget about your homework.\",\n",
       "  'Your teacher said you missed 7 assignments in a row!',\n",
       "  'So? History is boring!',\n",
       "  'I suppose historians are boring, too?',\n",
       "  \"No way, Gramps. You're the best!\",\n",
       "  'Then do it for me!',\n",
       "  'Your teacher said you could help me for extra credit.',\n",
       "  'A boring old shirt.',\n",
       "  'Just this old slip from 1916.',\n",
       "  'Do I have to?',\n",
       "  'What the-',\n",
       "  'I have an idea.',\n",
       "  \"He's wrong about old shirts and his name rhymes with \\\\smells\\\\...\",\n",
       "  'BUT WELLS STOLE TEDDY!',\n",
       "  'Could be. But we need evidence.',\n",
       "  \"Fine. Let's investigate!\",\n",
       "  \"Don't worry, Gramps. I'll find Teddy!\",\n",
       "  \"Please let me know if you do. It's important!\",\n",
       "  'I need to find Wells right away! Do you know where he is?',\n",
       "  'I need to find Wells!!!',\n",
       "  \"I can't calm down. This is important!\",\n",
       "  \"I don't have time for this, Gramps.\",\n",
       "  'Teddy is still missing!',\n",
       "  \"Let's follow those scratch marks!\",\n",
       "  \"I can't go with you. I need to take the artifact upstairs.\",\n",
       "  \"It's okay, Gramps. I'll go by myself.\",\n",
       "  'You stole Teddy! How could you?!',\n",
       "  \"No he hasn't!\",\n",
       "  \"Yes, he has. I've seen him eating homework and important papers, too.\",\n",
       "  'Come on, Teddy.',\n",
       "  \"Let's go find Gramps!\",\n",
       "  'I think I can help with your animal problem.',\n",
       "  \"Ha! I don't need your help.\",\n",
       "  \"Fine. Then I guess you don't want a real, live badger for the exhibit.\",\n",
       "  \"Oh, trust me. He'll make time.\",\n",
       "  'Um... what did you want me to do again?',\n",
       "  'Head over to the Basketball Center.',\n",
       "  'Hopefully you can find some clues!',\n",
       "  'I should stay and look for clues!',\n",
       "  'Where should I go again?',\n",
       "  'You could try the archivist. Maybe he can help you find Wells!',\n",
       "  'Hi, Mrs. M.',\n",
       "  'Head back to the museum. Your gramps is waiting for you.',\n",
       "  \"I don't need that right now.\",\n",
       "  'Meetings are BORING!',\n",
       "  \"I feel like I'm forgetting something.\",\n",
       "  'Gramps is the best historian ever!',\n",
       "  'This button never works!',\n",
       "  \"Why don't you go play with your grampa?\",\n",
       "  \"Look at that! It's the bee's knees!\",\n",
       "  \"Well, I did SOME of those. I just couldn't find them!\",\n",
       "  'Did you do all of them?',\n",
       "  'No... because history is boring!',\n",
       "  'Hooray, a boring old shirt.',\n",
       "  'Hot Dog! I knew it!',\n",
       "  'Ooh, I like clues!',\n",
       "  'Hopefully you can rustle up some clues!',\n",
       "  'I got here and the whole place was ransacked!',\n",
       "  'Hold your horses, Jo.',\n",
       "  '*grumble grumble*',\n",
       "  'And you are?',\n",
       "  \"I don't have time for kids.\",\n",
       "  'Now if only I could read this thing. Blasted tiny letters...',\n",
       "  'Knew what?',\n",
       "  'Did you have a question or not?',\n",
       "  'Yes!',\n",
       "  \"You're still here? I'm trying to work!\",\n",
       "  'Run along to the university.',\n",
       "  'Ooh, thanks!',\n",
       "  'Now I just need to find all the cleaners from wayyyy back in 1916.',\n",
       "  'Yikes... this could take a while.',\n",
       "  'Hi! *cough*',\n",
       "  'Can you help-',\n",
       "  '*cough cough*',\n",
       "  'Can you help me-',\n",
       "  '*COUGH COUGH COUGH*',\n",
       "  'Um, are you okay?',\n",
       "  \"Oh, I'm fine! Just a little hoarse.\",\n",
       "  'Ha! What do you call a pony with a sore throat?',\n",
       "  'Huh?',\n",
       "  'A little horse!',\n",
       "  \"Ha! You're funny.\",\n",
       "  'I got that one from my Gramps!',\n",
       "  'Can you help me? I need to find the owner of this slip.',\n",
       "  \"Yup, that's him!\",\n",
       "  \"Unless you're too busy horsing around.\",\n",
       "  'Ha! Good one.',\n",
       "  \"You look like you're on a mission.\",\n",
       "  'Two missions, actually!',\n",
       "  'Oh my!',\n",
       "  'I need to find Wells right away!! Do you know where he is?',\n",
       "  \"Calm down, kid. I haven't seen him.\",\n",
       "  \"I think it's a flag! Pretty spiffy, eh?\",\n",
       "  \"Great Scott, you're right!\",\n",
       "  \"Jo! I can't go with you. I need to take the artifact upstairs.\",\n",
       "  '\\\\u00f0\\\\u0178\\\\u02dc\\\\u00ad',\n",
       "  '\\\\u00e2\\\\u009d\\\\u00a4\\\\u00ef\\\\u00b8\\\\u008f',\n",
       "  'GRRRRRRR',\n",
       "  'GAH! And what is THAT doing out of its cage?!',\n",
       "  '\\\\u00f0\\\\u0178\\\\u02dc\\\\u0090',\n",
       "  'Teddy! Did you really eat his lunch?',\n",
       "  \"Did you steal Gramps's paperwork too?!\",\n",
       "  'And my homework?!?!',\n",
       "  'See?!',\n",
       "  \"That thing's a monster!\",\n",
       "  \"I don't have time for this.\",\n",
       "  'YEAH!',\n",
       "  'Wait- me?',\n",
       "  \"You can't just steal Jolie's pet. Don't you know badgers are protected animals?\",\n",
       "  'Besides, he looks friendly to me.',\n",
       "  'Wha?!',\n",
       "  '\\\\u00f0\\\\u0178\\\\u02dc\\\\u009d',\n",
       "  \"Teddy! I'm sure glad to see you.\",\n",
       "  'Gadzooks! Poor critter.',\n",
       "  'Aha! Good catch, Jo.',\n",
       "  'Not sure. Do I look like a deer expert to you?',\n",
       "  'Ugh. I have to head over there and check out the animals.',\n",
       "  'FINE. That possum better not scratch my leather seats...',\n",
       "  \"He's a badger!\",\n",
       "  '\\\\u00f0\\\\u0178\\\\u00a7\\\\u02dc',\n",
       "  'Yoga does sound nice.',\n",
       "  \"But cranes can't do yoga, Teddy!\",\n",
       "  '\\\\u00f0\\\\u0178\\\\u008d\\\\u00a9',\n",
       "  \"Cranes don't eat donuts!\",\n",
       "  'Besides, you just ate my last snack.',\n",
       "  \"Gah. I can't believe this.\",\n",
       "  \"I'm a historian, not a zookeeper!\",\n",
       "  'And this place is dirty, and itchy, and-',\n",
       "  'I love it!',\n",
       "  \"Of course you do. You've got a rodent following you around.\",\n",
       "  \"Actually, badgers aren't rodents-\",\n",
       "  'Whatever.',\n",
       "  'Great. Just great. Could this day get any worse?!',\n",
       "  \"Yes!!! I'm saved!\",\n",
       "  'A real, live ferret!',\n",
       "  \"He's. A. Badger.\",\n",
       "  'And we still need to figure out that flag!',\n",
       "  \"Fine, fine. Let's see...\",\n",
       "  'A vexy-wha?',\n",
       "  'Ooh... \\\\Ecology flag, by Ron Cobb.\\\\',\n",
       "  'The boss is gonna love it!!!',\n",
       "  \"You again! Don't let him hurt me!\",\n",
       "  '\\\\u00f0\\\\u0178\\\\u2122\\\\u201e',\n",
       "  \"Actually, we're just here for some photos.\",\n",
       "  'Guess so!',\n",
       "  'YOU?!',\n",
       "  \"Just please, don't let your badger eat them!\",\n",
       "  'I should help Gramps clean.',\n",
       "  \"Maybe there's a clue in this mess!\",\n",
       "  \"Poor Gramps! I should make sure he's okay.\",\n",
       "  'The archivist said I should look in the stacks.',\n",
       "  'There should be some info about that symbol in my book.',\n",
       "  'I should go talk to Gramps!',\n",
       "  'Yeah. Thanks anyway.',\n",
       "  'What are you waiting for? The Stacks are right outside the door.',\n",
       "  'Yes! This cool old slip from 1916.',\n",
       "  'Are you okay?',\n",
       "  \"I'll be in the collection room. Come find me when you're ready to check out the artifact.\",\n",
       "  'Good luck!',\n",
       "  'What?!',\n",
       "  'Can I ride with you?',\n",
       "  \"Don't worry, he won't! (And he's a badger, by the way.)\",\n",
       "  'Ugh... I think that lynx is looking at me funny.',\n",
       "  \"Don't worry, Teddy won't eat your lunch anymore!\",\n",
       "  \"We're just looking for photos for the flag display.\",\n",
       "  \"Weren't you going to check out our microfiche?\",\n",
       "  \"I'm sure you'll find Theodora in there somewhere!\",\n",
       "  \"But I hear the museum's got one on the loose!\",\n",
       "  'Well? What are you still doing here?',\n",
       "  'So much cleaning to do...',\n",
       "  'I should check out that pair of glasses.',\n",
       "  'I should ask the librarian where to go next.',\n",
       "  \"Check out the archives. They've got tons of old photos!\",\n",
       "  'I used to have a magnifying glass around here\\\\u00e2\\\\u20ac\\\\u00a6',\n",
       "  \"Come on, kid. You're slowing me down.\",\n",
       "  \"Did you drop something, Dear? There's a card on the floor.\",\n",
       "  'Take a look!',\n",
       "  'I should see what Gramps is up to!',\n",
       "  'I found it!',\n",
       "  'Theodora wearing the shirt!',\n",
       "  'You better get to the capitol!',\n",
       "  'Nice decorations.',\n",
       "  'Did you drop something, Dear?',\n",
       "  'Gramps said to look for clues. Better look around.',\n",
       "  'I should find out if she can help me!',\n",
       "  'Ooh, nice decorations!',\n",
       "  'The libarian said I could find some information on Youmans in here...',\n",
       "  'Have a look at the artifact!',\n",
       "  'What is it, Teddy?',\n",
       "  'Oh no... they got sick from polluted water?',\n",
       "  'Poor foxes!',\n",
       "  'I should ask the librarian why Wells was here.',\n",
       "  \"I wonder if there's a clue in those business cards...\",\n",
       "  'Thanks. Did you figure out the shirt?'],\n",
       " 562)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list = train_df[\"text\"].unique().tolist()\n",
    "name_list, len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['intro',\n",
       "  'gramps',\n",
       "  'teddy',\n",
       "  'photo',\n",
       "  nan,\n",
       "  'notebook',\n",
       "  'retirement_letter',\n",
       "  'tobasement',\n",
       "  'janitor',\n",
       "  'toentry',\n",
       "  'groupconvo',\n",
       "  'report',\n",
       "  'boss',\n",
       "  'wells',\n",
       "  'directory',\n",
       "  'tocollection',\n",
       "  'cs',\n",
       "  'tunic',\n",
       "  'tunic.hub.slip',\n",
       "  'tostacks',\n",
       "  'outtolunch',\n",
       "  'tocloset',\n",
       "  'tomap',\n",
       "  'tunic.historicalsociety',\n",
       "  'tunic.kohlcenter',\n",
       "  'plaque',\n",
       "  'plaque.face.date',\n",
       "  'togrampa',\n",
       "  'tunic.capitol_0',\n",
       "  'chap1_finale',\n",
       "  'chap1_finale_c',\n",
       "  'tocloset_dirty',\n",
       "  'what_happened',\n",
       "  'trigger_scarf',\n",
       "  'trigger_coffee',\n",
       "  'tunic.capitol_1',\n",
       "  'tofrontdesk',\n",
       "  'archivist',\n",
       "  'magnify',\n",
       "  'tunic.humanecology',\n",
       "  'worker',\n",
       "  'businesscards',\n",
       "  'businesscards.card_0.next',\n",
       "  'businesscards.card_1.next',\n",
       "  'businesscards.card_bingo.next',\n",
       "  'businesscards.card_bingo.bingo',\n",
       "  'tohallway',\n",
       "  'tunic.drycleaner',\n",
       "  'logbook',\n",
       "  'logbook.page.bingo',\n",
       "  'tunic.library',\n",
       "  'tomicrofiche',\n",
       "  'reader',\n",
       "  'reader.paper0.next',\n",
       "  'reader.paper1.next',\n",
       "  'reader.paper2.bingo',\n",
       "  'wellsbadge',\n",
       "  'journals',\n",
       "  'journals.hub.topics',\n",
       "  'journals.pic_0.next',\n",
       "  'journals.pic_1.next',\n",
       "  'journals.pic_2.bingo',\n",
       "  'chap2_finale_c',\n",
       "  'ch3start',\n",
       "  'seescratches',\n",
       "  'tocage',\n",
       "  'glasses',\n",
       "  'directory.closeup.archivist',\n",
       "  'key',\n",
       "  'unlockdoor',\n",
       "  'confrontation',\n",
       "  'savedteddy',\n",
       "  'tocollectionflag',\n",
       "  'groupconvo_flag',\n",
       "  'tunic.capitol_2',\n",
       "  'tunic.wildlife',\n",
       "  'coffee',\n",
       "  'crane_ranger',\n",
       "  'remove_cup',\n",
       "  'expert',\n",
       "  'tracks',\n",
       "  'tracks.hub.deer',\n",
       "  'tunic.flaghouse',\n",
       "  'flag_girl',\n",
       "  'colorbook',\n",
       "  'reader_flag',\n",
       "  'reader_flag.paper0.next',\n",
       "  'reader_flag.paper1.next',\n",
       "  'reader_flag.paper2.bingo',\n",
       "  'archivist_glasses',\n",
       "  'journals_flag',\n",
       "  'journals_flag.hub.topics_old',\n",
       "  'journals_flag.hub.topics',\n",
       "  'journals_flag.pic_0.bingo',\n",
       "  'journals_flag.pic_0.next',\n",
       "  'chap4_finale_c',\n",
       "  'block_tocollection',\n",
       "  'reader.paper2.next',\n",
       "  'journals.pic_2.next',\n",
       "  'lockeddoor',\n",
       "  'reader.paper2.prev',\n",
       "  'reader.paper0.prev',\n",
       "  'reader_flag.paper1.prev',\n",
       "  'journals_flag.pic_0_old.next',\n",
       "  'journals_flag.pic_1_old.next',\n",
       "  'reader.paper1.prev',\n",
       "  'block_0',\n",
       "  'journals_flag.pic_1.bingo',\n",
       "  'block_magnify',\n",
       "  'journals_flag.pic_1.next',\n",
       "  'doorblock',\n",
       "  'journals_flag.pic_2.bingo',\n",
       "  'journals_flag.pic_2.next',\n",
       "  'door_block_clean',\n",
       "  'door_block_talk',\n",
       "  'block',\n",
       "  'reader_flag.paper2.next',\n",
       "  'block_tomap2',\n",
       "  'reader_flag.paper0.prev',\n",
       "  'journals_flag.pic_2_old.next',\n",
       "  'need_glasses',\n",
       "  'block_nelson',\n",
       "  'block_tomap1',\n",
       "  'reader_flag.paper2.prev',\n",
       "  'block_badge',\n",
       "  'fox',\n",
       "  'block_badge_2',\n",
       "  'block_1'],\n",
       " 128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fqid_list = train_df[\"fqid\"].unique().tolist()\n",
    "fqid_list, len(fqid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tunic.historicalsociety.closet',\n",
       "  'tunic.historicalsociety.basement',\n",
       "  'tunic.historicalsociety.entry',\n",
       "  'tunic.historicalsociety.collection',\n",
       "  'tunic.historicalsociety.stacks',\n",
       "  'tunic.kohlcenter.halloffame',\n",
       "  'tunic.capitol_0.hall',\n",
       "  'tunic.historicalsociety.closet_dirty',\n",
       "  'tunic.historicalsociety.frontdesk',\n",
       "  'tunic.humanecology.frontdesk',\n",
       "  'tunic.drycleaner.frontdesk',\n",
       "  'tunic.library.frontdesk',\n",
       "  'tunic.library.microfiche',\n",
       "  'tunic.capitol_1.hall',\n",
       "  'tunic.historicalsociety.cage',\n",
       "  'tunic.historicalsociety.collection_flag',\n",
       "  'tunic.wildlife.center',\n",
       "  'tunic.flaghouse.entry',\n",
       "  'tunic.capitol_2.hall'],\n",
       " 19)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_list = train_df[\"room_fqid\"].unique().tolist()\n",
    "room_list, len(room_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cols = [\"session_id\", \"level_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Function\n",
    "def feature_engineer(train_df):\n",
    "    # Create a list of new dataframes for each feature\n",
    "    dfs = []\n",
    "\n",
    "    agg_functions = {c: [\"mean\", \"std\", \"sum\", \"max\", \"min\"] for c in numerical_cols}\n",
    "\n",
    "    for c, funcs in agg_functions.items():\n",
    "        tmp = train_df.groupby(groupby_cols)[c].agg(funcs)\n",
    "        tmp.columns = [f\"{c}_{agg_name}\" for agg_name in funcs]\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    for c in categorical_cols:\n",
    "        tmp = train_df.groupby(groupby_cols)[c].agg(\"nunique\")\n",
    "        tmp.name = f\"{tmp.name}_nunique\"\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    for c in event_list:\n",
    "        train_df[c] = (train_df[\"event_name\"] == c).astype(np.int8)\n",
    "\n",
    "    for c in event_list:\n",
    "        tmp = train_df.groupby(groupby_cols).agg({c: \"sum\", \"elapsed_time\": \"sum\"})\n",
    "        tmp.rename(\n",
    "            columns={c: f\"{c}_sum\", \"elapsed_time\": f\"{c}_elapsed_time_sum\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    for c in room_list:\n",
    "        train_df[c] = (train_df[\"room_fqid\"] == c).astype(np.int8)\n",
    "\n",
    "    for c in room_list:\n",
    "        tmp = train_df.groupby(groupby_cols)[c].agg(\"sum\")\n",
    "        tmp.name = f\"{tmp.name}_sum\"\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    # Frequency encoding of fqid\n",
    "    fqid_counts = train_df['fqid'].value_counts()\n",
    "    train_df['fqid_freq_encoded'] = train_df['fqid'].map(fqid_counts)\n",
    "\n",
    "    tmp = train_df.groupby(groupby_cols)['fqid_freq_encoded'].agg([\"mean\", \"sum\", \"max\", \"min\"])\n",
    "    tmp.columns = [f\"fqid_freq_encoded_{agg_name}\" for agg_name in tmp.columns]\n",
    "    dfs.append(tmp)\n",
    "\n",
    "    train_df.drop(columns=['fqid', 'fqid_freq_encoded'], inplace=True)\n",
    "\n",
    "    # Frequency encoding of text\n",
    "    text_counts = train_df['text'].value_counts()\n",
    "    train_df['text_freq_encoded'] = train_df['text'].map(text_counts)\n",
    "\n",
    "    tmp = train_df.groupby(groupby_cols)['text_freq_encoded'].agg([\"mean\", \"sum\", \"max\", \"min\"])\n",
    "    tmp.columns = [f\"text_freq_encoded_{agg_name}\" for agg_name in tmp.columns]\n",
    "    dfs.append(tmp)\n",
    "\n",
    "    train_df.drop(columns=['text', 'text_freq_encoded'], inplace=True)\n",
    "\n",
    "    df = pd.concat(dfs, axis=1).fillna(-1)\n",
    "    df = df.reset_index().set_index(\"session_id\")\n",
    "\n",
    "    _ = gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thong.lam\\Documents\\LHL\\Data Immensive\\W9\\D5\\PredictStudentPerformance.ipynb Cell 20\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thong.lam/Documents/LHL/Data%20Immensive/W9/D5/PredictStudentPerformance.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thong.lam/Documents/LHL/Data%20Immensive/W9/D5/PredictStudentPerformance.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, skips[k] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thong.lam/Documents/LHL/Data%20Immensive/W9/D5/PredictStudentPerformance.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(train_csv_path, skiprows\u001b[39m=\u001b[39mrows, nrows\u001b[39m=\u001b[39mreads[k])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thong.lam/Documents/LHL/Data%20Immensive/W9/D5/PredictStudentPerformance.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df \u001b[39m=\u001b[39m feature_engineer(train_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thong.lam/Documents/LHL/Data%20Immensive/W9/D5/PredictStudentPerformance.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m all_chunks\u001b[39m.\u001b[39mappend(df)\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# Process train_df in chunks\n",
    "all_chunks = []\n",
    "for k in range(pieces):\n",
    "    rows = 0\n",
    "    if k > 0:\n",
    "        rows = range(1, skips[k] + 1)\n",
    "        train_df = pd.read_csv(train_csv_path, skiprows=rows, nrows=reads[k])\n",
    "\n",
    "    df = feature_engineer(train_df)\n",
    "    all_chunks.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean memory\n",
    "del train_df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all chunks\n",
    "df = pd.concat(all_chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "features = [c for c in df.columns if c != \"level_group\"]\n",
    "users = df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target dataframe\n",
    "gkf = GroupKFold(n_splits=7)\n",
    "oof = pd.DataFrame(\n",
    "    data=np.zeros((len(users), 18)),\n",
    "    index=users,\n",
    ")\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for each group and question\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X=df, groups=df.index)):\n",
    "    print(f\"Fold {i + 1} => \", end=\"\")\n",
    "\n",
    "    xgb_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 4,\n",
    "        \"n_estimators\": 1000,\n",
    "        \"early_stopping_rounds\": 50,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.4,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    for t in range(1, 19):\n",
    "        if t <= 3:\n",
    "            grp = \"0-4\"\n",
    "        elif t <= 13:\n",
    "            grp = \"5-12\"\n",
    "        elif t <= 22:\n",
    "            grp = \"13-22\"\n",
    "\n",
    "        # Train data\n",
    "        train_x = df.iloc[train_index]\n",
    "        train_x = train_x.loc[train_x.level_group == grp]\n",
    "        train_users = train_x.index.values\n",
    "        train_y = target_df.loc[target_df.q == t].set_index(\"session\").loc[train_users]\n",
    "\n",
    "        # Valid data\n",
    "        valid_x = df.iloc[test_index]\n",
    "        valid_x = valid_x.loc[valid_x.level_group == grp]\n",
    "        valid_users = valid_x.index.values\n",
    "        valid_y = target_df.loc[target_df.q == t].set_index(\"session\").loc[valid_users]\n",
    "\n",
    "        # Train model\n",
    "        clf = XGBClassifier(**xgb_params)\n",
    "        clf.fit(\n",
    "            train_x[features].astype(\"float32\"),\n",
    "            train_y[\"correct\"],\n",
    "            eval_set=[(valid_x[features].astype(\"float32\"), valid_y[\"correct\"])],\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(f\"{t}({clf.best_ntree_limit}), \", end=\"\")\n",
    "\n",
    "        # Save model and predict valid oof\n",
    "        models[f\"{grp}_{t}\"] = clf\n",
    "        oof.loc[valid_users, t - 1] = clf.predict_proba(\n",
    "            valid_x[features].astype(\"float32\")\n",
    "        )[:, 1]\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Df with 18 columns\n",
    "true = oof.copy()\n",
    "for k in range(18):\n",
    "    # Get labels for each question\n",
    "    tmp = target_df.loc[target_df.q == k + 1].set_index(\"session\").loc[users]\n",
    "    true[k] = tmp.correct.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best threshold for converting probabilities to labels\n",
    "# Initialize variables\n",
    "scores = []\n",
    "thresholds = []\n",
    "\n",
    "# Best score and threshold variables\n",
    "best_score = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# Iterate over all possible thresholds\n",
    "for threshold in np.arange(0.4, 0.81, 0.01):\n",
    "    print(f\"{threshold:.02f}, \", end=\"\")\n",
    "    preds = (oof.values.reshape((-1)) > threshold).astype(\"int\")\n",
    "    m = f1_score(true.values.reshape((-1)), preds, average=\"macro\")\n",
    "    scores.append(m)\n",
    "    thresholds.append(threshold)\n",
    "    if m > best_score:\n",
    "        best_score = m\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot threshold vs. f1_score\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(thresholds, scores, \"-o\", color=\"blue\")\n",
    "plt.scatter([best_threshold], [best_score], color=\"blue\", s=300, alpha=1)\n",
    "plt.xlabel(\"Threshold\", size=14)\n",
    "plt.ylabel(\"Validation F1 Score\", size=14)\n",
    "plt.title(\n",
    "    f\"Threshold vs. F1_Score with Best F1_Score = {best_score:.3f} at Best Threshold = {best_threshold:.3}\",\n",
    "    size=18,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print f1 score for each question\n",
    "print(\"When using optimal threshold...\")\n",
    "for k in range(18):\n",
    "    # Compute f1 score for each question\n",
    "    m = f1_score(\n",
    "        true[k].values, (oof[k].values > best_threshold).astype(\"int\"), average=\"macro\"\n",
    "    )\n",
    "    print(f\"Q{k}: F1 =\", m)\n",
    "\n",
    "# Compute overall F1 score\n",
    "m = f1_score(\n",
    "    true.values.reshape((-1)),\n",
    "    (oof.values.reshape((-1)) > best_threshold).astype(\"int\"),\n",
    "    average=\"macro\",\n",
    ")\n",
    "print(\"==> Overall F1 =\", m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
